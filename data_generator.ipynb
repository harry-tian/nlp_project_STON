{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8497aea6",
   "metadata": {},
   "source": [
    "# 1. Designing cloze tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdcf340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0191e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = np.random.choice\n",
    "\n",
    "male_names = []\n",
    "female_names = []\n",
    "for row in csv.DictReader(open(\"most_common_female_names.csv\")):\n",
    "    female_names.append(row['name'])\n",
    "for row in csv.DictReader(open(\"most_common_male_names.csv\")):\n",
    "    male_names.append(row['name'])\n",
    "subject_pool = [\"his name is\",\"her name is\", \"my name is\", \"your name is\"]\n",
    "n = len(male_names)\n",
    "exclude = ['Ewan', 'Alastair', 'Euan', 'Calum', 'Alasdair', 'Greig', 'Martyn', 'Kieran', 'Kristopher', 'Keiran', 'Ciaran', 'Finlay', 'Arran', 'Keir', 'Kian', 'Lennon', 'Kenzie', 'Alfie', 'Jayden', 'Zak', 'Kayden', 'Kaiden', 'Ruaridh', 'Olly', 'Callan', 'Jaxon', 'Lachlan', 'Arlo', 'Innes', 'Ruairidh', 'Struan', 'Lorna', 'Kirsty', 'Shona', 'Catriona', 'Morag', 'Kirsten', 'Kirsteen', 'Lynsey', 'Aileen', 'Arlene', 'Mhairi', 'Gayle', 'Leanne', 'Lyndsey', 'Lyndsay', 'Charlene', 'Linsey', 'Eilidh', 'Hayley', 'Alana', 'Siobhan', 'Rachael', 'Ashleigh', 'Kayleigh', 'Jemma', 'Linzi', 'Jodie', 'Michaela', 'Sinead', 'Kerri', 'Kirstie', 'Nicolle', 'Rebekah', 'Hollie', 'Chantelle', 'Abbie', 'Niamh', 'Rhiannon', 'Caitlyn', 'Kaitlin', 'Ciara', 'Meghan', 'Lauryn', 'Ailsa', 'Morven', 'Cerys', 'Kiera', 'Freya', 'Zara', 'Orla', 'Keira', 'Neve', 'Abi', 'Abbi', 'Alisha', 'Mya', 'Maisie', 'Imogen', 'Nieve', 'Miley', 'Mollie', 'Laila', 'Mirren', 'Ayla', 'Mila', 'Esme', 'Arianna', 'Thea', 'Ariana', 'Lillie', 'Hallie', 'Aila', 'Myla', 'Aoife', 'Lottie', 'Lyla', 'Remi', 'Maeve', 'Ayda', 'Arabella']\n",
    "exclude.extend(['Iain', 'Graeme', 'Alistair', 'Roderick', 'Gregor', 'Callum', 'Niall', 'Barrie', 'Antony', 'Declan', 'Aidan', 'Rhys', 'Reece', 'Hamish', 'Conner', 'Ronan', 'Aiden', 'Mackenzie', 'Brodie', 'Luca', 'Ollie', 'Reuben', 'Brody', 'Zachary', 'Jax', 'Lyle', 'Finley', 'Myles', 'Gillian', 'Jacqueline', 'Lesley', 'Pauline', 'Lorraine', 'Tracey', 'Lynne', 'Yvonne', 'Joanne', 'Gail', 'Joanna', 'Maureen', 'Mandy', 'Jillian', 'Vicky', 'Stacey', 'Gemma', 'Kimberley', 'Adele', 'Kylie', 'Robyn', 'Caitlin', 'Aimee', 'Cara', 'Demi', 'Bethany', 'Toni', 'Abigail', 'Iona', 'Isla', 'Kelsey', 'Carla', 'Kaitlyn', 'Jasmine', 'Skye', 'Rosie', 'Kayla', 'Elle', 'Ella', 'Millie', 'Ava', 'Evie', 'Alyssa', 'Poppy', 'Isabella', 'Charley', 'Layla', 'Libby', 'Lexi', 'Amelie', 'Phoebe', 'Lexie', 'Lucie', 'Sienna', 'Gracie', 'Rowan', 'Sofia', 'Lacey', 'Emilia', 'Lola', 'Darcy', 'Aria', 'Matilda', 'Elsie', 'Georgie', 'Sadie', 'Arya', 'Callie', 'Penelope', 'Cora', 'Evelyn', 'Alba'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3bcc3c",
   "metadata": {},
   "source": [
    "## Name-to-entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "878629f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_0():\n",
    "    sentences = []\n",
    "    answers = []\n",
    "\n",
    "    for name in male_names:\n",
    "        if name in exclude: continue\n",
    "        sentence = []\n",
    "        context = [subject_pool[0], name, \".\"]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        question = [\"So\", subject_pool[0], \"[MASK]\", \".\"]\n",
    "        sentence.extend(question)\n",
    "\n",
    "        sentence = \" \".join(sentence)\n",
    "        sentences.append(sentence)\n",
    "        answers.append(name)\n",
    "\n",
    "    for name in female_names:\n",
    "        if name in exclude: continue\n",
    "        sentence = []\n",
    "        context = [subject_pool[1], name, \".\"]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        question = [\"So\", subject_pool[1], \"[MASK]\", \".\"]\n",
    "        sentence.extend(question)\n",
    "\n",
    "        sentence = \" \".join(sentence)\n",
    "        sentences.append(sentence)\n",
    "        answers.append(name)\n",
    "\n",
    "    return sentences, answers\n",
    "\n",
    "def name_1():\n",
    "    sentences = []\n",
    "    answers = []\n",
    "\n",
    "    for n1, n2 in zip(male_names, female_names[:n]):\n",
    "        if n1 in exclude: continue\n",
    "        sentence = []\n",
    "        context = [subject_pool[0], n1]\n",
    "        sentence.extend(context)\n",
    "\n",
    "        sent = [\"and\", subject_pool[1], n2, \".\"]\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        question = [\"So\", subject_pool[0], \"[MASK]\", \".\"]\n",
    "        sentence.extend(question)\n",
    "\n",
    "        sentence = \" \".join(sentence)\n",
    "        sentences.append(sentence)\n",
    "        answers.append(n1)\n",
    "    return sentences, answers\n",
    "\n",
    "def name_2():\n",
    "    all_names = male_names + female_names\n",
    "    my_names = choice(all_names, n)\n",
    "    sentences = []\n",
    "    answers = []\n",
    "\n",
    "    for n1, n2, n3 in zip(male_names, female_names[:n], my_names):\n",
    "        if n1 in exclude: continue\n",
    "        sentence = []\n",
    "        context = [subject_pool[0], n1]\n",
    "        sentence.extend(context)\n",
    "\n",
    "        sent = [\",\", subject_pool[1], n2]\n",
    "        sentence.extend(sent)\n",
    "\n",
    "        sent = [\"and\", subject_pool[2], n3, \".\"]\n",
    "        sentence.extend(sent)\n",
    "\n",
    "        question = [\"So\", subject_pool[0], \"[MASK]\", \".\"]\n",
    "        sentence.extend(question)\n",
    "\n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "    return sentences, answers\n",
    "\n",
    "def name_3():\n",
    "    all_names = male_names + female_names\n",
    "    my_names = choice(all_names, n)\n",
    "    your_names = choice(all_names, n)\n",
    "    sentences = []\n",
    "    answers = []\n",
    "\n",
    "    for n1, n2, n3, n4 in zip(male_names, female_names[:n], my_names, your_names):\n",
    "        if n1 in exclude: continue\n",
    "        sentence = []\n",
    "        context = [subject_pool[0], n1]\n",
    "        sentence.extend(context)\n",
    "\n",
    "        sent = [\",\", subject_pool[1], n2]\n",
    "        sentence.extend(sent)\n",
    "\n",
    "        sent = [\",\", subject_pool[2], n3]\n",
    "        sentence.extend(sent)\n",
    "\n",
    "        sent = [\"and\", subject_pool[3], n4, \".\"]\n",
    "        sentence.extend(sent)\n",
    "\n",
    "        question = [\"So\", subject_pool[0], \"[MASK]\", \".\"]\n",
    "        sentence.extend(question)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "    return sentences, answers\n",
    "\n",
    "sentences, answers = name_0()\n",
    "with open(\"name_num_attractors_0.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "sentences, answers = name_1()\n",
    "with open(\"name_num_attractors_1.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "sentences, answers = name_2()\n",
    "with open(\"name_num_attractors_2.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "    \n",
    "sentences, answers = name_3()\n",
    "with open(\"name_num_attractors_3.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd288f5",
   "metadata": {},
   "source": [
    "## Familial relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542c0cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_pool = [\"is the partner of\", \"is the parent of\", \"is married to\", \"is the son of\", \"is the daughter of\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c255e4f1",
   "metadata": {},
   "source": [
    "### parent-child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8a6ab91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parents0():\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    all_names = male_names + female_names\n",
    "    for A in all_names:\n",
    "        if A in exclude: \n",
    "            continue\n",
    "        sentence = [A]\n",
    "        B = A\n",
    "        while B == A:\n",
    "            B = str(choice(all_names, 1)[0])\n",
    "        if A in male_names:\n",
    "            context = [subject_pool[3], B]\n",
    "        else:\n",
    "            context = [subject_pool[4], B]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        sent = ['.', 'So', B, subject_pool[1], \"[MASK]\", '.']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(A)\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "def parents1():\n",
    "    np.random.seed(1)\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    for _ in range(n):\n",
    "        entities = choice(all_names, 4, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        n3 = str(entities[2])\n",
    "        n4 = str(entities[3])\n",
    "        \n",
    "        sentence = [n1]\n",
    "        if n1 in males:\n",
    "            context = [subject_pool[3], n2]\n",
    "        else:\n",
    "            context = [subject_pool[4], n2]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        if n3 in males:\n",
    "            attractor = [',', 'and', n3, subject_pool[3], n4]\n",
    "        else:\n",
    "            attractor = [',', 'and', n3, subject_pool[4], n4]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        sent = [',', 'So', n2, subject_pool[1], '[MASK]', '.']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "    \n",
    "    return sentences, answers\n",
    "\n",
    "def parents2():\n",
    "    np.random.seed(2)\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    for _ in range(n):\n",
    "        entities = choice(all_names, 6, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        n3 = str(entities[2])\n",
    "        n4 = str(entities[3])\n",
    "        n5 = str(entities[4])\n",
    "        n6 = str(entities[5])\n",
    "        \n",
    "        sentence = [n1]\n",
    "        if n1 in male_names:\n",
    "            context = [subject_pool[3], n2]\n",
    "        else:\n",
    "            context = [subject_pool[4], n2]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        if n3 in male_names:\n",
    "            attractor = [',', n3, subject_pool[3], n4]\n",
    "        else:\n",
    "            attractor = [',', n3, subject_pool[4], n4]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        if n5 in male_names:\n",
    "            attractor = [',', 'and', n5, subject_pool[3], n6]\n",
    "        else:\n",
    "            attractor = [',', 'and', n5, subject_pool[4], n6]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        sent = [',', 'So', n2, subject_pool[1], '[MASK]', '.']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "    \n",
    "    return sentences, answers\n",
    "\n",
    "def parents3():\n",
    "    np.random.seed(3)\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    for _ in range(n):\n",
    "        entities = choice(all_names, 8, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        n3 = str(entities[2])\n",
    "        n4 = str(entities[3])\n",
    "        n5 = str(entities[4])\n",
    "        n6 = str(entities[5])\n",
    "        n7 = str(entities[6])\n",
    "        n8 = str(entities[7])\n",
    "        \n",
    "        sentence = [n1]\n",
    "        if n1 in male_names:\n",
    "            context = [subject_pool[3], n2]\n",
    "        else:\n",
    "            context = [subject_pool[4], n2]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        if n3 in male_names:\n",
    "            attractor = [',', n3, subject_pool[3], n4]\n",
    "        else:\n",
    "            attractor = [',', n3, subject_pool[4], n4]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        if n5 in male_names:\n",
    "            attractor = [',', n5, subject_pool[3], n6]\n",
    "        else:\n",
    "            attractor = [',', n5, subject_pool[4], n6]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        if n7 in male_names:\n",
    "            attractor = [',', 'and', n7, subject_pool[3], n8]\n",
    "        else:\n",
    "            attractor = [',', 'and', n7, subject_pool[4], n8]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        sent = [',', 'So', n2, subject_pool[1], '[MASK]', '.']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "    \n",
    "    return sentences, answers\n",
    "\n",
    "\n",
    "sentences, answers = parents0()\n",
    "with open(\"parents_num_attractors_0.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "sentences, answers = parents1()\n",
    "with open(\"parents_num_attractors_1.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "sentences, answers = parents2()\n",
    "with open(\"parents_num_attractors_2.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "    \n",
    "sentences, answers = parents3()\n",
    "with open(\"parents_num_attractors_3.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44891397",
   "metadata": {},
   "source": [
    "### marriage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd074a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def marry0():\n",
    "    np.random.seed(0)\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        sentence = []\n",
    "        entities = choice(all_names, 2, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        context = [n1, subject_pool[2], n2]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        sent = ['. So', n2, subject_pool[0], '[MASK] .']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "def marry1():\n",
    "    np.random.seed(1)\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        sentence = []\n",
    "        entities = choice(all_names, 4, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        n3 = str(entities[2])\n",
    "        n4 = str(entities[3])\n",
    "        context = [n1, subject_pool[2], n2]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        attractor=[', and', n3, subject_pool[2], n4]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        sent = ['. So', n2, subject_pool[0], '[MASK] .']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "def marry2():\n",
    "    np.random.seed(2)\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        sentence = []\n",
    "        entities = choice(all_names, 6, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        n3 = str(entities[2])\n",
    "        n4 = str(entities[3])\n",
    "        n5 = str(entities[4])\n",
    "        n6 = str(entities[5])\n",
    "        context = [n1, subject_pool[2], n2]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        attractor = [',', n3, subject_pool[2], n4]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        attractor=[', and', n5, subject_pool[2], n5]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        sent = ['. So', n2, subject_pool[0], '[MASK] .']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "def marry3():\n",
    "    np.random.seed(3)\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        sentence = []\n",
    "        entities = choice(all_names, 8, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        n3 = str(entities[2])\n",
    "        n4 = str(entities[3])\n",
    "        n5 = str(entities[4])\n",
    "        n6 = str(entities[5])\n",
    "        n7 = str(entities[6])\n",
    "        n8 = str(entities[7])\n",
    "        context = [n1, subject_pool[2], n2]\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        attractor = [',', n3, subject_pool[2], n4]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        attractor = [',', n7, subject_pool[2], n8]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        attractor=[', and', n5, subject_pool[2], n5]\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        sent = ['. So', n2, subject_pool[0], '[MASK] .']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        answers.append(n1)\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "sentences, answers = marry0()\n",
    "with open(\"marry_num_attractors_0.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "sentences, answers = marry1()\n",
    "with open(\"marry_num_attractors_1.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "sentences, answers = marry2()\n",
    "with open(\"marry_num_attractors_2.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "    \n",
    "sentences, answers = marry3()\n",
    "with open(\"marry_num_attractors_3.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99342fcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "13af058c",
   "metadata": {},
   "source": [
    "## Age-calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4171e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_pool = ['next year'] * 4 #['next year', 'four years later', 'last year', 'four years ago']\n",
    "ages = ['sixteen', 'nineteen', 'fourteen', 'eleven']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "511b4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def age_cal0():\n",
    "    np.random.seed(0)\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        sentence = []\n",
    "        entities = choice(all_names, 1, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        context = [n1, 'is fifteen years old']\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        prompt = choice([0, 1, 2, 3], 1, replace = False).item()\n",
    "        #sent = ['.', subject_pool[prompt], ',', 'the age of', n1, 'is [MASK] .']\n",
    "        sent = ['.', subject_pool[prompt], ',', 'the age of', n1, 'is [MASK] .']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        #answers.append(ages[prompt])\n",
    "        answers.append('sixteen')\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "\n",
    "def age_cal1():\n",
    "    np.random.seed(1)\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        sentence = []\n",
    "        entities = choice(all_names, 2, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        context = [n1, 'is fifteen years old']\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        random_age = str(choice(ages, 1, replace = False)[0])\n",
    "        attractor =[', and', n2, 'is', random_age, 'years old']\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        prompt = choice([0, 1, 2, 3], 1, replace = False).item()\n",
    "        sent = ['.', subject_pool[prompt], ',', 'the age of', n1, 'is [MASK] .']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        #answers.append(ages[prompt])\n",
    "        answers.append('sixteen')\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "def age_cal2():\n",
    "    np.random.seed(2)\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        sentence = []\n",
    "        entities = choice(all_names, 3, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        n3 = str(entities[2])\n",
    "        context = [n1, 'is fifteen years old']\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        random_age = str(choice(ages, 1, replace = False)[0])\n",
    "        attractor = [',', n2, 'is', random_age, 'years old']\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        random_age = str(choice(ages, 1, replace = False)[0])\n",
    "        attractor =[', and', n3, 'is', random_age, 'years old']\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        prompt = choice([0, 1, 2, 3], 1, replace = False).item()\n",
    "        sent = ['.', subject_pool[prompt], ',', 'the age of', n1, 'is [MASK] .']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        #answers.append(ages[prompt])\n",
    "        answers.append('sixteen')\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "def age_cal3():\n",
    "    np.random.seed(3)\n",
    "    males = [name for name in male_names if name not in exclude]\n",
    "    females = [name for name in female_names if name not in exclude]\n",
    "    all_names = males + females\n",
    "    sentences = []\n",
    "    answers = []\n",
    "    \n",
    "    for _ in range(n):\n",
    "        sentence = []\n",
    "        entities = choice(all_names, 4, replace = False)\n",
    "        n1 = str(entities[0])\n",
    "        n2 = str(entities[1])\n",
    "        n3 = str(entities[2])\n",
    "        n4 = str(entities[3])\n",
    "        context = [n1, 'is fifteen years old']\n",
    "        sentence.extend(context)\n",
    "        \n",
    "        random_age = str(choice(ages, 1, replace = False)[0])\n",
    "        attractor = [',', n2, 'is', random_age, 'years old']\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        random_age = str(choice(ages, 1, replace = False)[0])\n",
    "        attractor =[',', n3, 'is', random_age, 'years old']\n",
    "        sentence.extend(attractor)\n",
    "\n",
    "        random_age = str(choice(ages, 1, replace = False)[0])\n",
    "        attractor =[', and', n4, 'is', random_age, 'years old']\n",
    "        sentence.extend(attractor)\n",
    "        \n",
    "        prompt = choice([0, 1, 2, 3], 1, replace = False).item()\n",
    "        sent = ['.', subject_pool[prompt], ',', 'the age of', n1, 'is [MASK] .']\n",
    "        sentence.extend(sent)\n",
    "        \n",
    "        sentences.append(\" \".join(sentence))\n",
    "        #answers.append(ages[prompt])\n",
    "        answers.append('sixteen')\n",
    "        \n",
    "    return sentences, answers\n",
    "\n",
    "\n",
    "sentences, answers = age_cal0()\n",
    "with open(\"agecal_num_attractors_0.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "sentences, answers = age_cal1()\n",
    "with open(\"agecal_num_attractors_1.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "\n",
    "sentences, answers = age_cal2()\n",
    "with open(\"agecal_num_attractors_2.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n",
    "    \n",
    "sentences, answers = age_cal3()\n",
    "with open(\"agecal_num_attractors_3.csv\", \"w\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames = ['sentence', 'answer'])\n",
    "    writer.writeheader()\n",
    "    writer.writerows([{'sentence': sentence, 'answer': answer} for sentence, answer in zip(sentences, answers)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d42f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d399f069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa9c622",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81014364",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d25a0172",
   "metadata": {},
   "source": [
    "# Performance of the LM models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89896961",
   "metadata": {},
   "source": [
    "## Name to entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eb0cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import pipeline\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be7fd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(data_dir):\n",
    "    f = open(data_dir)\n",
    "    reader = csv.DictReader(f)\n",
    "\n",
    "    targets = []\n",
    "    sentences = []\n",
    "    for row in reader:\n",
    "        sentence = row['sentence']\n",
    "        target = row['answer']\n",
    "        \n",
    "        targets.append(target)\n",
    "        sentences.append(sentence)\n",
    "\n",
    "    return sentences, targets\n",
    "\n",
    "\n",
    "def generate(model, text, tokenizer, n=10):\n",
    "    # text = 'his name is Henry , her name is Mary , my name is Twyla and your name is Geneva . his name is'\n",
    "    input_ids = torch.tensor([tokenizer.encode(text)]).to(device)\n",
    "    output = model.generate(\n",
    "        input_ids,\n",
    "        do_sample = True, \n",
    "        max_length = len(input_ids[0]) + 1, \n",
    "        top_k = 50, \n",
    "        top_p = 0.95, \n",
    "        num_return_sequences = n\n",
    "    )\n",
    "    answers = tokenizer.decode(output[:,-1], skip_special_tokens = True)\n",
    "\n",
    "    return answers\n",
    "\n",
    "def eval(model, texts, targets, verbose = False):\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    errors = []\n",
    "\n",
    "    if \"roberta\" in model:\n",
    "        texts = [text.replace(\"[MASK]\", \"<mask>\") for text in texts]\n",
    "    elif \"gpt\" in model:\n",
    "        texts = [text.replace(\" [MASK] .\", \"\") for text in texts]\n",
    "\n",
    "    if \"bert\" in model:\n",
    "        if torch.cuda.is_available():\n",
    "            x = 0\n",
    "        else:\n",
    "            x = -1\n",
    "        predict = pipeline('fill-mask', model = model, device = x)\n",
    "        for text, target in tqdm(zip(texts, targets)):\n",
    "            total += 1\n",
    "            pred = predict(text)[0]\n",
    "            pred = pred[\"token_str\"]\n",
    "            if pred.strip().lower() == target.strip().lower():\n",
    "                correct += 1\n",
    "            else:\n",
    "                errors.append(target)\n",
    "            if verbose: \n",
    "                print(text, pred, target)\n",
    "\n",
    "    elif \"gpt\" in model:\n",
    "        tokenizer = GPT2Tokenizer.from_pretrained(model)\n",
    "        model = GPT2LMHeadModel.from_pretrained(model, pad_token_id=tokenizer.eos_token_id).to(device)\n",
    "        for text, target in tqdm(zip(texts, targets)):\n",
    "            total += 1\n",
    "            preds = generate(model, text, tokenizer, n=30)\n",
    "            if target.strip().lower() in preds.lower():\n",
    "                correct += 1\n",
    "            else:\n",
    "                errors.append(target)\n",
    "            if verbose: \n",
    "                print(target, preds)\n",
    "\n",
    "    return correct/total, errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c17d300c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    models = [\"bert-base-uncased\"]#, \n",
    "              #\"bert-large-uncased\", \n",
    "              #\"roberta-base\", \n",
    "              #\"roberta-large\", \n",
    "              #\"gpt2\", \n",
    "              #\"gpt2-medium\"] \n",
    "    fieldnames = [\"model\", 0, 1, 2, 3]\n",
    "    results = []\n",
    "\n",
    "    data_dir = 'raw_data/simple_SVO/names/'\n",
    "    out_dir = data_dir + \"results.csv\"\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"{model}:\\n\" + 100 * '-')\n",
    "        result = dict.fromkeys(fieldnames)\n",
    "        result[\"model\"] = model\n",
    "        for n in [0, 1, 2, 3]:\n",
    "            print(f\"n={n}:\\n\" + 100 * '-')\n",
    "            f = data_dir + f\"num_attractors_{n}.csv\"\n",
    "            texts,targets = get_data(f)\n",
    "            acc, err = eval(model, texts, targets, verbose = False)\n",
    "            result[n] = acc\n",
    "        results.append(result)\n",
    "        print(results)\n",
    "\n",
    "    with open(out_dir, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames = fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327e0354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e2d5dce2",
   "metadata": {},
   "source": [
    "## Familial relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "84cc0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    models = [\"bert-base-uncased\"]#, \n",
    "              #\"bert-large-uncased\", \n",
    "              #\"roberta-base\", \n",
    "              #\"roberta-large\", \n",
    "              #\"gpt2\", \n",
    "              #\"gpt2-medium\"] \n",
    "    fieldnames = [\"model\", 0, 1, 2, 3]\n",
    "    results = []\n",
    "\n",
    "    data_dir = 'raw_data/simple_SVO/parents/'\n",
    "    out_dir = data_dir + \"results.csv\"\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"{model}:\\n\" + 100 * '-')\n",
    "        result = dict.fromkeys(fieldnames)\n",
    "        result[\"model\"] = model\n",
    "        for n in [0, 1, 2, 3]:\n",
    "            print(f\"n={n}:\\n\" + 100 * '-')\n",
    "            f = data_dir + f\"num_attractors_{n}.csv\"\n",
    "            texts,targets = get_data(f)\n",
    "            acc, err = eval(model, texts, targets, verbose = False)\n",
    "            result[n] = acc\n",
    "        results.append(result)\n",
    "        print(results)\n",
    "\n",
    "    with open(out_dir, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames = fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ed8f0591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "n=0:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "369it [00:27, 13.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:22, 10.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=2:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:26,  9.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:29,  8.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'bert-base-uncased', 0: 0.997289972899729, 1: 0.5591836734693878, 2: 0.42857142857142855, 3: 0.43673469387755104}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b48e32c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    models = [\"bert-base-uncased\"]#, \n",
    "              #\"bert-large-uncased\", \n",
    "              #\"roberta-base\", \n",
    "              #\"roberta-large\", \n",
    "              #\"gpt2\", \n",
    "              #\"gpt2-medium\"] \n",
    "    fieldnames = [\"model\", 0, 1, 2, 3]\n",
    "    results = []\n",
    "\n",
    "    data_dir = 'raw_data/simple_SVO/marry/'\n",
    "    out_dir = data_dir + \"results.csv\"\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"{model}:\\n\" + 100 * '-')\n",
    "        result = dict.fromkeys(fieldnames)\n",
    "        result[\"model\"] = model\n",
    "        for n in [0, 1, 2, 3]:\n",
    "            print(f\"n={n}:\\n\" + 100 * '-')\n",
    "            f = data_dir + f\"num_attractors_{n}.csv\"\n",
    "            texts,targets = get_data(f)\n",
    "            acc, err = eval(model, texts, targets, verbose = False)\n",
    "            result[n] = acc\n",
    "        results.append(result)\n",
    "        print(results)\n",
    "\n",
    "    with open(out_dir, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames = fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "09d070c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "n=0:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:18, 13.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:21, 11.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=2:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:24,  9.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:27,  8.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'bert-base-uncased', 0: 0.9877551020408163, 1: 0.4816326530612245, 2: 0.5755102040816327, 3: 0.6530612244897959}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12882ba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2580333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d2cda2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a5a47e4",
   "metadata": {},
   "source": [
    "### Age-calculus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "998a937f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    models = [\"bert-base-uncased\"]#, \n",
    "              #\"bert-large-uncased\", \n",
    "              #\"roberta-base\", \n",
    "              #\"roberta-large\", \n",
    "              #\"gpt2\", \n",
    "              #\"gpt2-medium\"] \n",
    "    fieldnames = [\"model\", 0, 1, 2, 3]\n",
    "    results = []\n",
    "\n",
    "    data_dir = 'raw_data/simple_SVO/age_cal/'\n",
    "    out_dir = data_dir + \"results.csv\"\n",
    "\n",
    "    for model in models:\n",
    "        print(f\"{model}:\\n\" + 100 * '-')\n",
    "        result = dict.fromkeys(fieldnames)\n",
    "        result[\"model\"] = model\n",
    "        for n in [0, 1, 2, 3]:\n",
    "            print(f\"n={n}:\\n\" + 100 * '-')\n",
    "            f = data_dir + f\"num_attractors_{n}.csv\"\n",
    "            texts,targets = get_data(f)\n",
    "            acc, err = eval(model, texts, targets, verbose = False)\n",
    "            result[n] = acc\n",
    "        results.append(result)\n",
    "        print(results)\n",
    "\n",
    "    with open(out_dir, 'w', encoding='UTF8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames = fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6fe1d059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert-base-uncased:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "n=0:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:17, 13.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=1:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:22, 11.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=2:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:25,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n=3:\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "245it [00:28,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'model': 'bert-base-uncased', 0: 0.0, 1: 0.0, 2: 0.004081632653061225, 3: 0.0}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b78e10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1ecb23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375b6370",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dabf703",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca1276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990313fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3389599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a401d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs351",
   "language": "python",
   "name": "cs351"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
